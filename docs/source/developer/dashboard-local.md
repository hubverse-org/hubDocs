# Local Dashboard Workflow

One of the most daunting aspects of the dashboard workflows are the GitHub
workflows in [hubverse-org/hub-dashboard-control-room](https://github.com/hubverse-org/hub-dashboard-control-room).
However, the dashboard does not exclusively rely on the GitHub workflow and it
can be built locally. The diagram below shows a how we get a dashboard website
(`site`) by using the pre-compute tools along with the dashboard and hub
repositories (note that `hub-dash-site-builder` is building the entire site,
not just `index.html`).

```{mermaid}
:name: local-workflow
:alt: A flowchart that demonstrates flow of data from the hub and dashboard to the final site with the tools that build each component labelling arrows.
:config: {"theme": "base", "themeVariables": {"primaryColor": "#dbeefb", "primaryBorderColor": "#3c88be"}}
flowchart BT
    hub["hub repository"]
    dashboard["dashboard repository"]
    ptc/data>ptc data]
    predevals/data>evals data]
    subgraph pre-compute toolchain
      hub-dashboard-predtimechart[\hub-dashboard-predtimechart/]
      hubPredEvalsData[\hubPredEvalsData/]
      hub-dash-site-builder[\hub-dash-site-builder/]
    end
    subgraph site
        index.html([index.html])
        forecast.html([forecast.html])
        eval.html([eval.html])
    end
    dashboard -->|site-config.yml| hub-dash-site-builder
    hub-dash-site-builder --> site
    hub -->|time-series data|hub-dashboard-predtimechart
    dashboard -->|predtimechart-config.yml|hub-dashboard-predtimechart
    hub-dashboard-predtimechart --> ptc/data
    hub -->|oracle data|hubPredEvalsData
    dashboard -->|predevals-config.yml|hubPredEvalsData
    hubPredEvalsData --> predevals/data
    predevals/data -.-> eval.html
    ptc/data -.-> forecast.html
```

This page will demonstrate that workflow using a practical example.

```
#!/usr/bin/env bash
set -eo pipefail
#
# PURPOSE:
#   This script demonstrates the dashboard workflow process as it
#   exists **independent of GitHub workflows**. This script is not
#   concerned about where data are stored or when they are updated.
#
# RATIONALE:
#   Building a dashboard website requires three tools:
#   1. one to build the predtimechart data and options
#   2. one to build the predevals data and options
#   3. one to build the static website
#
#   These take data from two sources:
#   1. the dashboard repository
#   2. the hub repository
#
#   The GitHub workflows bind all of these together, but these end
#   up being complex because they deal with **issues of deployment**
#   that is, where the data are stored and when they are updated.
#   These issues are a separate layer of complexity that can be
#   addressed once you understand the underlying build process.
#
# REQUIRED SOFTWARE:
#
#   gh     --- needed for interacting with the GitHub API
#   yq     --- needed to get the hub information from the site config
#   uv     --- python client, runs hub-dashboard-predtimechart
#   git    --- needed for cloning repositories
#   tree   --- displays a graphical structure of the folders
#   docker --- runs hub-dash-site-builder and hubpredevalsdata-docker
#
# BROAD STEPS
#
# After this script is run, we will end up with a temporary directory that
# has the following structure:
# $tmp
# ├── dashboard
# │   ├── _site #............ generated by hub-dash-site-builder
# │   │   └── resources
# │   │       ├── css
# │   │       ├── evals     # local copies
# │   │       └── forecasts #
# │   ├── data
# │   │   ├── evals # ....... generated by hubPredEvalsData-docker
# │   │   │   └── scores
# │   │   └── ptc   # ....... generated by hub-dashboard-predtimechart
# │   │       ├── forecasts
# │   │       └── targets
# │   └── pages
# └── hub
#     ├── auxiliary-data
#     ├── hub-config
#     ├── model-metadata
#     ├── model-output
#     ├── raw-data
#     ├── src
#     └── target-data
#
# Below are the broad steps with the directories that are created:
#
#   SETUP
#   1. create a temporary directory...................... $tmp
#   2. clone the dashboard............................... $tmp/dashboard
#   3. get the hub name from the dashboard and clone it.. $tmp/hub
#
#   GENERATE FORECASTS (python)
#   1. create targets output dir..... $tmp/dashboard/ptc/targets
#   2. create forecasts output dir... $tmp/dashboard/ptc/forecasts
#   3. download tool and generate both targets and forecasts
#
#   GENERATE EVALS (docker)
#   1. create evals output dir... $tmp/dashboard/evals
#   2. download tool and generate evals data
#
#   GENERATE SITE (docker)
#   1. download tool and generate site... $tmp/dashboard/_site
#      NOTE: Because the data are local, the data will be copied into the site.
echo "Welcome to the hubverse dashboard demonstration"
echo
# SETUP ------------------------------------------------------------------------
#
# For the setup, we will need to clone the hub dashboard repository
dash_repo=${1:-reichlab/metrocast-dashboard}
tmp=$(mktemp -d)
dash="$tmp/dashboard"
hub="$tmp/hub"
echo "Cloning $dash_repo into $dash ..."
echo
git clone "https://github.com/${dash_repo}.git" "$dash"

repo=$(yq '.hub' "$dash/site-config.yml")
echo "Cloning $repo into $hub ..."
echo
git clone "https://github.com/${repo}.git" "$hub"
echo
echo "Tree representation of the current setup before generation"
tree -d -L 4 -I 'epi*|site_libs' $tmp

# GENERATE FORECASTS -----------------------------------------------------------
#
# We need a place to generate the forecasts, so we place them
# in the `data/ptc` folder inside the dashboard. The reason why
# we place them inside the dashboard and not outside is because
# the docker container expects the data to be in the same folder.
echo
echo
echo "Generating forecast data"
echo "--------------------------------------------------"
echo
echo "... Creating data/ptc/targets and data/ptc/forecasts in $dash"
echo
mkdir -p $dash/data/ptc/{targets,forecasts}

echo "... Setting up python environment in $dash ..."
echo
uv venv --seed "$dash/.venv"
source "$dash/.venv/bin/activate"

latest=$(gh api -X GET "repos/hubverse-org/hub-dashboard-predtimechart/releases/latest" --jq ".tag_name")
echo "... Installing hub-dashboard-predtimechart@$latest"
echo
uv run pip install --quiet --upgrade pip
uv run pip install --quiet "git+https://github.com/hubverse-org/hub-dashboard-predtimechart@$latest"

echo "... Generating target data"
echo
ptc_generate_target_json_files \
  $hub \
  $dash/predtimechart-config.yml \
  $dash/data/ptc/targets

echo "... Generating forecast data"
echo
ptc_generate_json_files \
  $hub \
  $dash/predtimechart-config.yml \
  $dash/data/ptc/predtimechart-options.json \
  $dash/data/ptc/forecasts
echo "Forecasts done!"
echo

# GENERATE EVALUATIONS ---------------------------------------------------------
#
# This runs from a docker image. Note here that `/project` is the working
# directory of the image, so the strategy is:
#
# 1. link the dashboard directory to the /project working directory and
#    reference any files or directories with relative paths
# 2. link the hub directory to a new /hub directory and
#    reference any files or directories with absolute paths
#
# NOTE: the hub must be local, but the target data can be a downloadable file.
# NOTE: we will change the script arguments in the future so that the oracle
#       data can be fetched using hubData tooling.
echo
echo
echo "Generating Evaluations Data"
echo "--------------------------------------------------"
echo
mkdir -p $dash/data/evals
docker pull --platform=linux/amd64 ghcr.io/hubverse-org/hubpredevalsdata-docker:main
docker run --rm -it \
  --platform=linux/amd64 \
  -v "$dash":"/project" \
  -v "$hub":"/hub" \
  ghcr.io/hubverse-org/hubpredevalsdata-docker:main \
  create-predevals-data.R \
    -h "/hub" \
    -c "predevals-config.yml" \
    -d "/hub/target-data/oracle-output.csv" \
    -o "data/evals"

# GENERATE WEBSITE -------------------------------------------------------------
#
# In the GitHub workflows, this process is run separately because the data can
# be fetched from a branch on the dashboard itself. This demonstrates the local
# data workflow.
#
# The website is generated with a docker container whose working directory is
# /site. Unlike the above script, this assumes that everything is inside the
# working directory, so the strategy here is:
#
# 1. link the dashboard directory to the /site working directory and reference
#    any files or directories with relative paths.
echo
echo
echo "Generating Website"
echo "--------------------------------------------------"
echo
mkdir -p $dash/data/evals
docker pull --platform=linux/amd64 ghcr.io/hubverse-org/hub-dash-site-builder:latest
docker run --rm -it \
  --platform=linux/amd64 \
  -v "$dash":"/site" \
  ghcr.io/hubverse-org/hub-dash-site-builder:latest \
  render.sh \
  -p "data/ptc" -e "data/evals" \
  -o "_site"

echo "the site is in"
echo "$dash/_site"

echo "Done!"
echo
echo "Here is a tree representation of the output. Note that dashboard/_site"
echo "and dashboard/data are new directories that we generated with our processes"
tree -d -L 4 -I 'epi*|site_libs' $tmp
echo "The demonstration files are in"
echo "$tmp"
```
